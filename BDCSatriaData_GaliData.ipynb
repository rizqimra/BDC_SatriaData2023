{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULBVgNkHqyPi"
      },
      "source": [
        "# Unzip Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYmQUyd_pg0K"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "root_dir = '/content/drive/MyDrive/SatriaData'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uN18TmxMGTs6",
        "outputId": "4b8475d5-f441-47a2-fc97-1816341a79be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TT73MANPp5jR"
      },
      "outputs": [],
      "source": [
        "# !pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkeBg1IdE8sw"
      },
      "outputs": [],
      "source": [
        "# !rm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsrMA1RXpngJ",
        "outputId": "ef212b26-7303-44dd-89d9-fd1b2118ba5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " CNN_acc.png\n",
            " DataTest.csv\n",
            "'Data Test for BDC 2023 - Penyisihan'\n",
            "'Data Test for BDC 2023 - Penyisihan.zip'\n",
            " DataTrain\n",
            " DataTrain.csv\n",
            "'Data Train for BDC 2023 - Penyisihan'\n",
            "'Data Train for BDC 2023 - Penyisihan.zip'\n",
            " __MACOSX\n"
          ]
        }
      ],
      "source": [
        "os.chdir(root_dir)\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfPYcvGppqKQ"
      },
      "outputs": [],
      "source": [
        "# !unzip 'Data Train for BDC 2023 - Penyisihan.zip' -d .\n",
        "# !unzip 'Data Test for BDC 2023 - Penyisihan.zip' -d .\n",
        "\n",
        "# # setelah ini, pindahkan file .csv di luar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTgvQxU-IUvD"
      },
      "outputs": [],
      "source": [
        "# !mv Data\\ Train\\ for\\ BDC\\ 2023\\ -\\ Penyisihan/DataTrain.csv .\n",
        "# !mv Data\\ Test\\ for\\ BDC\\ 2023\\ -\\ Penyisihan/DataTest.csv ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZ4NgQtfr6eg"
      },
      "outputs": [],
      "source": [
        "train_data_dir = os.path.join(root_dir, \"Data Train for BDC 2023 - Penyisihan\")\n",
        "test_data_dir = os.path.join(root_dir, \"Data Test for BDC 2023 - Penyisihan\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCKrHO7OJwW-"
      },
      "outputs": [],
      "source": [
        "# !ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSJdOgulrXze"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "classes = list(string.ascii_uppercase)\n",
        "\n",
        "for i in range(0, 10):\n",
        "  classes.append(str(i))\n",
        "\n",
        "os.mkdir(\"DataTrain\")\n",
        "# for c in classes:\n",
        "#   os.mkdir(os.path.join('DataTrain', c))\n",
        "\n",
        "# os.mkdir(\"DataTest\")\n",
        "# for c in classes:\n",
        "#   os.mkdir(os.path.join('DataTest', c))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9mKOaU0q2mV"
      },
      "source": [
        "# Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJePBI3qq3gu"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "from collections import namedtuple\n",
        "from skimage.filters import threshold_local\n",
        "from skimage import segmentation\n",
        "from skimage import measure\n",
        "from imutils import perspective\n",
        "import imutils\n",
        "\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNuzdEz5-QmP"
      },
      "outputs": [],
      "source": [
        "classes = list(string.ascii_uppercase)\n",
        "\n",
        "for i in range(0, 10):\n",
        "  classes.append(str(i))\n",
        "\n",
        "numeric_classes = [i for i in range(len(classes))]\n",
        "\n",
        "labeltoidx = dict(zip(classes, numeric_classes))\n",
        "idxtolabel = dict(zip(numeric_classes, classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6zJTK--j1Xs0",
        "outputId": "18601fb6-1f0d-4181-8833-0c75efa05c2a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0 Vehicleregistrationplate      NameofFile\n",
              "0           0                    A7814  DataTrain1.png\n",
              "1           1                  B1074QO  DataTrain2.png\n",
              "2           2                  B1031QO  DataTrain3.png\n",
              "3           3                  B187EDA  DataTrain4.png\n",
              "4           4                  B1089VD  DataTrain5.png"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3144c96e-3fe8-43a1-905c-329be99eda93\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Vehicleregistrationplate</th>\n",
              "      <th>NameofFile</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A7814</td>\n",
              "      <td>DataTrain1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>B1074QO</td>\n",
              "      <td>DataTrain2.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>B1031QO</td>\n",
              "      <td>DataTrain3.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>B187EDA</td>\n",
              "      <td>DataTrain4.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>B1089VD</td>\n",
              "      <td>DataTrain5.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3144c96e-3fe8-43a1-905c-329be99eda93')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3144c96e-3fe8-43a1-905c-329be99eda93 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3144c96e-3fe8-43a1-905c-329be99eda93');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df_train = pd.read_csv('DataTrain.csv', delimiter=\";\")\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-PZdEUpazbpE",
        "outputId": "06684a30-718f-4d21-8926-d5959a755c5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0   Name of File\n",
              "0           0  DataTest1.png\n",
              "1           1  DataTest2.png\n",
              "2           2  DataTest3.png\n",
              "3           3  DataTest4.png\n",
              "4           4  DataTest5.png"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a464b841-fde5-4780-a87c-e41571b7dec5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Name of File</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>DataTest1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>DataTest2.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>DataTest3.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>DataTest4.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>DataTest5.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a464b841-fde5-4780-a87c-e41571b7dec5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a464b841-fde5-4780-a87c-e41571b7dec5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a464b841-fde5-4780-a87c-e41571b7dec5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df_test = pd.read_csv('DataTest.csv', delimiter=\";\")\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5FzxHrC9JOR"
      },
      "outputs": [],
      "source": [
        "# !ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRYeU9MKq60_"
      },
      "outputs": [],
      "source": [
        "def preprocess_images_train(df):\n",
        "  image_data = []\n",
        "  label_data = []\n",
        "  # image_data = np.array([])\n",
        "  image_paths = df.NameofFile.values\n",
        "  labels = df.Vehicleregistrationplate.values\n",
        "\n",
        "  for label, image_file in zip(labels, image_paths):\n",
        "    # Load gambar\n",
        "    img = cv2.imread(os.path.join(train_data_dir, image_file))\n",
        "    # Resize gambar\n",
        "    r = 800.0 / img.shape[1]\n",
        "    dim = (800, int(img.shape[0]*r))\n",
        "    img = cv2.resize(img, dim, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    # mengubah gambar menjadi grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.cvtColor(gray, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Noise Reduction\n",
        "    gray = cv2.bilateralFilter(gray, 11, 17, 17)\n",
        "\n",
        "    # edge detection\n",
        "    edged = cv2.Canny(gray, 70, 200) #Perform Edge detection\n",
        "    # edged = cv2.Sobel(gray, cv2.CV_64F, 1, 1, 5)\n",
        "\n",
        "    # melakukan segmentasi menggunakan MSER\n",
        "    mser = cv2.MSER_create()\n",
        "    # regions, boundingBoxes = mser.detectRegions(gray)\n",
        "    regions, boundingBoxes = mser.detectRegions(edged)\n",
        "    boundingBoxes = np.unique(boundingBoxes, axis=0)\n",
        "\n",
        "    candidates = []\n",
        "    # candidates = np.array([])\n",
        "    x_prev = 0\n",
        "\n",
        "    for i, box in enumerate(boundingBoxes):\n",
        "      x, y, w, h = box\n",
        "\n",
        "      if x in range(x_prev+5):\n",
        "        continue\n",
        "      else:\n",
        "        x_prev = x\n",
        "        cropped = img[y:y+h, x:x+w]\n",
        "        cy, cx, _ = cropped.shape\n",
        "        if (40 < cx < 140) and (100 < cy < 200):\n",
        "        # if (1.65 < cropped.shape[0]/cropped.shape[1] < 3.7):\n",
        "          V = cropped\n",
        "          T = threshold_local(V, 57, offset=15, method=\"gaussian\")\n",
        "          thresh = (V > T).astype(\"uint8\") * 255\n",
        "          thresh = cv2.bitwise_not(thresh)\n",
        "          candidates.append(thresh)\n",
        "\n",
        "          # candidates.append(cropped)\n",
        "\n",
        "    label_char = [*label]\n",
        "\n",
        "    # if len(label_char) == len(candidates):\n",
        "    if len(label_char) > len(candidates):\n",
        "      # print(\"found\")\n",
        "      for i, thimg in enumerate(candidates):\n",
        "        cv2.imwrite(f\"DataTrain/{image_file[:-4]}-{i}_{label_char[i]}.png\", cv2.cvtColor(thimg, cv2.COLOR_BGR2GRAY))\n",
        "        # cv2.imwrite(f\"DataTrain/{label_char[i]}/{image_file[:-4]}-{i}.png\", cv2.cvtColor(thimg, cv2.COLOR_BGR2GRAY))\n",
        "\n",
        "        # Rotate and save the images\n",
        "        angle = random.randint(0, 360)  # Random rotation angle\n",
        "        (h, w) = thimg.shape[:2]\n",
        "        center = (w // 2, h // 2)\n",
        "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "        rotated = cv2.warpAffine(thimg, M, (w, h))\n",
        "        cv2.imwrite(f\"DataTrain/{image_file[:-4]}-{i}_{label_char[i]}_rotated.png\", rotated)\n",
        "\n",
        "    # image_data.append(candidates)\n",
        "  return image_data #[N, candidate]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zB9X_zgzAYW"
      },
      "outputs": [],
      "source": [
        "def preprocess_images_test(df):\n",
        "  image_data = []\n",
        "  label_data = []\n",
        "  # image_data = np.array([])\n",
        "  image_paths = df.NameofFile.values\n",
        "  labels = df.Vehicleregistrationplate.values\n",
        "\n",
        "  for label, image_file in zip(labels, image_paths):\n",
        "    # Load gambar\n",
        "    img = cv2.imread(os.path.join(train_data_dir, image_file))\n",
        "    # Resize gambar\n",
        "    r = 800.0 / img.shape[1]\n",
        "    dim = (800, int(img.shape[0]*r))\n",
        "    img = cv2.resize(img, dim, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    # mengubah gambar menjadi grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.cvtColor(gray, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Noise Reduction\n",
        "    gray = cv2.bilateralFilter(gray, 11, 17, 17)\n",
        "\n",
        "    # edge detection\n",
        "    edged = cv2.Canny(gray, 70, 200) #Perform Edge detection\n",
        "    # edged = cv2.Sobel(gray, cv2.CV_64F, 1, 1, 5)\n",
        "\n",
        "    # melakukan segmentasi menggunakan MSER\n",
        "    mser = cv2.MSER_create()\n",
        "    # regions, boundingBoxes = mser.detectRegions(gray)\n",
        "    regions, boundingBoxes = mser.detectRegions(edged)\n",
        "    boundingBoxes = np.unique(boundingBoxes, axis=0)\n",
        "\n",
        "    candidates = []\n",
        "    # candidates = np.array([])\n",
        "    x_prev = 0\n",
        "\n",
        "    for i, box in enumerate(boundingBoxes):\n",
        "      x, y, w, h = box\n",
        "\n",
        "      if x in range(x_prev+5):\n",
        "        continue\n",
        "      else:\n",
        "        x_prev = x\n",
        "        cropped = img[y:y+h, x:x+w]\n",
        "        cy, cx, _ = cropped.shape\n",
        "        if (40 < cx < 140) and (100 < cy < 200):\n",
        "        # if (1.65 < cropped.shape[0]/cropped.shape[1] < 3.7):\n",
        "          V = cropped\n",
        "          T = threshold_local(V, 57, offset=15, method=\"gaussian\")\n",
        "          thresh = (V > T).astype(\"uint8\") * 255\n",
        "          thresh = cv2.bitwise_not(thresh)\n",
        "          candidates.append(thresh)\n",
        "\n",
        "          # candidates.append(cropped)\n",
        "\n",
        "    label_char = [*label]\n",
        "\n",
        "    # if len(label_char) == len(candidates):\n",
        "    if len(label_char) > len(candidates):\n",
        "      # print(\"found\")\n",
        "      for i, thimg in enumerate(candidates):\n",
        "        cv2.imwrite(f\"DataTrain/{image_file[:-4]}-{i}_{label_char[i]}.png\", cv2.cvtColor(thimg, cv2.COLOR_BGR2GRAY))\n",
        "        # cv2.imwrite(f\"DataTest/{label_char[i]}/{image_file[:-4]}-{i}.png\", cv2.cvtColor(thimg, cv2.COLOR_BGR2GRAY))\n",
        "\n",
        "    # image_data.append(candidates)\n",
        "  return image_data #[N, candidate]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEgPLvJEr0tD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de76a1ce-5770-4217-80ee-7d9c6e3b1481"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skimage/_shared/utils.py:348: RuntimeWarning: Images with dimensions (M, N, 3) are interpreted as 2D+RGB by default. Use `multichannel=False` to interpret as 3D image with last dimension of length 3.\n",
            "  return func(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# # img_pth = os.listdir(train_data_dir)[25]\n",
        "# # images = preprocess_images([img_pth])\n",
        "\n",
        "# # results = preprocess_images(df_train.iloc[:100])\n",
        "results = preprocess_images_train(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdD28CpYzOWH"
      },
      "outputs": [],
      "source": [
        "# results = preprocess_images_test(df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1q9mzOQG_NC_"
      },
      "outputs": [],
      "source": [
        "# for c in classes:\n",
        "#   print(len(os.listdir(f\"DataTrain/{c}\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjrAxqSKzmTc"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbjiQiD5zm0Q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "from torchvision import transforms, datasets, models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHLXuGDjzpGt"
      },
      "outputs": [],
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((255,255)),\n",
        "    transforms.RandomRotation(45),\n",
        "    transforms.RandomPerspective(0.5, 0.1),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.3)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((255,255)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2ceRTeKzrtN"
      },
      "outputs": [],
      "source": [
        "# class CharDataset(torch.utils.data.Dataset):\n",
        "#     def __init__(self, dataset, transform=None):\n",
        "#         self.dataset = dataset\n",
        "#         self.transform = transform\n",
        "\n",
        "#     def __getitem__(self, index):\n",
        "#         x = dataset[index][0] if not self.transform else self.transform(dataset[index][0])\n",
        "#         y = dataset[index][1]\n",
        "#         return x, y\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(dataset)\n",
        "\n",
        "class ImageDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self,img_folder,transform):\n",
        "    self.transform=transform\n",
        "    self.img_folder=img_folder\n",
        "\n",
        "    self.image_names = os.listdir(img_folder) # \"DataTrain/{image_file[:-4]}-{i}_{label_char[i]}.png\"\n",
        "\n",
        "    # self.labels = np.array(self.csv.drop(['Id', 'Genre'], axis=1))\n",
        "    self.labels = np.array([x[-5] for x in self.image_names])\n",
        "\n",
        "#The __len__ function returns the number of samples in our dataset.\n",
        "  def __len__(self):\n",
        "    return len(self.image_names)\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    # image=cv2.imread(self.img_folder+self.image_names[index]+'.png')\n",
        "    image=cv2.imread(self.img_folder + \"/\" + self.image_names[index])\n",
        "    image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    image=self.transform(image)\n",
        "    targets=self.labels[index]\n",
        "\n",
        "    sample = {'image': image,'labels':targets}\n",
        "\n",
        "    return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tb0C2A405mT-"
      },
      "outputs": [],
      "source": [
        "data_dir = 'DataTrain'\n",
        "dataset = ImageDataset(data_dir, train_transforms)\n",
        "train_loader = torch.utils.data.DataLoader(dataset , batch_size=8, shuffle=False,\n",
        "                               num_workers=1, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMuoNyvM7j9D",
        "outputId": "42b65fab-2f19-438f-84d0-3f5e6d6f44ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 3, 255, 255])\n"
          ]
        }
      ],
      "source": [
        "sample = next(iter(train_loader))\n",
        "print(sample['image'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDBu0bvd55bN",
        "outputId": "f606cae0-d1b0-4126-c954-67e74451c406"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24\n"
          ]
        }
      ],
      "source": [
        "num_classes = len(list(set(dataset.labels)))\n",
        "print(num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Guev0IOP7BWF"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.conv5 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(12544, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 36)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "        x = self.pool(F.relu(self.conv5(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "model_scratch = Model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVCImRT47QJG"
      },
      "outputs": [],
      "source": [
        "def viz(model_name, train_acc, val_acc, train_loss, val_loss):\n",
        "    epoch = range(1, len(train_acc) + 1)\n",
        "\n",
        "    plt.plot(epoch, train_acc, 'r', label='Training Acc')\n",
        "    plt.plot(epoch, val_acc, 'b', label='Validation Acc')\n",
        "    plt.title(model_name + ' training and validation acc')\n",
        "    plt.legend()\n",
        "    plt.savefig(model_name + '_acc.png')\n",
        "\n",
        "    plt.plot(epoch, train_loss, 'r', label='Training Loss')\n",
        "    plt.plot(epoch, val_loss, 'b', label='Validation Loss')\n",
        "    plt.title(model_name + ' training and validation loss')\n",
        "    plt.legend()\n",
        "    # plt.savefig(model_name + '_loss.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "IsV_7tKu7TzT",
        "outputId": "88bfb4bc-01ab-4247-afa6-72e81c3c75b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cuda ...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-2903840646ea>\u001b[0m in \u001b[0;36m<cell line: 79>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m# viz(\"CNN\", hist_train_acc, hist_val_acc, hist_train_loss, hist_val_loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0mtraining_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_scratch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-2903840646ea>\u001b[0m in \u001b[0;36mtraining_process\u001b[0;34m(model, n_epochs, train_loader)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainingdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainingdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabeltoidx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-2903840646ea>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainingdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainingdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabeltoidx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'd'"
          ]
        }
      ],
      "source": [
        "# def training_process(model, n_epochs, train_loader, val_loader):\n",
        "def training_process(model, n_epochs, train_loader):\n",
        "    # model_name = model\n",
        "    # model = model_list[model]\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model.to(device)\n",
        "    print('Training on {} ...'.format(device))\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
        "\n",
        "    val_loss_min = np.Inf  # track change in validation loss\n",
        "    hist_train_acc, hist_val_acc, hist_train_loss, hist_val_loss = [], [], [], []\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        t0 = time.time()\n",
        "        t_running_loss, v_running_loss, t_correct, t_total, v_correct, v_total = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
        "\n",
        "        model.train()\n",
        "        # for data, target in train_loader:\n",
        "        for trainingdata in train_loader:\n",
        "            # data, target = data.to(device), target.to(device)\n",
        "            data, target = trainingdata['image'], trainingdata['labels']\n",
        "            data = data.to(device)\n",
        "            target = [labeltoidx[t] for t in target]\n",
        "\n",
        "            target = torch.from_numpy(np.array(target)).to(device)\n",
        "\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            t_running_loss += loss.item()\n",
        "            _, predicted = output.max(1)\n",
        "            t_total += target.size(0)\n",
        "            t_correct += predicted.eq(target).sum().item()\n",
        "\n",
        "        train_acc = t_correct / t_total\n",
        "        train_loss = t_running_loss / len(train_loader)\n",
        "\n",
        "        # model.eval()\n",
        "        # for data, target in val_loader:\n",
        "        #     data, target = data.to(device), target.to(device)\n",
        "        #     output = model(data)\n",
        "        #     loss = criterion(output, target)\n",
        "\n",
        "        #     v_running_loss += loss.item()\n",
        "        #     _, predicted = output.max(1)\n",
        "        #     v_total += target.size(0)\n",
        "        #     v_correct += predicted.eq(target).sum().item()\n",
        "\n",
        "        # val_acc = v_correct / v_total\n",
        "        # val_loss = v_running_loss / len(val_loader)\n",
        "\n",
        "        # hist_train_acc.append(train_acc)\n",
        "        # hist_val_acc.append(val_acc)\n",
        "        # hist_train_loss.append(train_loss)\n",
        "        # hist_val_loss.append(val_loss)\n",
        "\n",
        "        t1 = time.time() - t0\n",
        "        # print(\n",
        "        #     'Epoch: {} \\tTrain Acc: {}/{}({:.2f}) \\tVal Acc: {}/{}({:.2f}) \\tTrain Loss: {:.4f} \\tVal Loss: {:.4f} \\tTraining time: {} seconds'.format(\n",
        "        #         epoch, t_correct, t_total, train_acc, v_correct, v_total, val_acc, train_loss, val_loss, t1))\n",
        "        print(\n",
        "            'Epoch: {} \\tTrain Acc: {}/{}({:.2f}) \\tTrain Loss: {:.4f} \\tTraining time: {} seconds'.format(\n",
        "                epoch, t_correct, t_total, train_acc, train_loss, t1))\n",
        "\n",
        "        # save model if validation loss has decreased\n",
        "        # if val_loss <= val_loss_min:\n",
        "        #     print('Validation loss decreased ({:.2f} --> {:.2f}).  Saving model ...'.format(val_loss_min, val_loss))\n",
        "        #     torch.save(model.state_dict(), model_name+'.pth')\n",
        "        #     val_loss_min = val_loss\n",
        "\n",
        "    # viz(\"CNN\", hist_train_acc, hist_val_acc, hist_train_loss, hist_val_loss)\n",
        "\n",
        "training_process(model_scratch, 100, train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-SWkkLSzWHv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGg22We3EB7A"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60_rDGQJFBAa"
      },
      "outputs": [],
      "source": [
        "def preprocess_single(image_path):\n",
        "  img = cv2.imread(image_path)\n",
        "\n",
        "  # Resize gambar\n",
        "  r = 800.0 / img.shape[1]\n",
        "  dim = (800, int(img.shape[0]*r))\n",
        "  img = cv2.resize(img, dim, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "  # mengubah gambar menjadi grayscale\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  gray = cv2.cvtColor(gray, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  # Noise Reduction\n",
        "  gray = cv2.bilateralFilter(gray, 11, 17, 17)\n",
        "\n",
        "  # edge detection\n",
        "  edged = cv2.Canny(gray, 70, 200) #Perform Edge detection\n",
        "\n",
        "  # melakukan segmentasi menggunakan MSER\n",
        "  mser = cv2.MSER_create()\n",
        "  # regions, boundingBoxes = mser.detectRegions(gray)\n",
        "  regions, boundingBoxes = mser.detectRegions(edged)\n",
        "  boundingBoxes = np.unique(boundingBoxes, axis=0)\n",
        "\n",
        "  # candidates = np.array([])\n",
        "  candidates = []\n",
        "  x_prev = 0\n",
        "\n",
        "  # imgboxed = img.copy()\n",
        "  for i, box in enumerate(boundingBoxes):\n",
        "    x, y, w, h = box\n",
        "    # cv2.rectangle(imgboxed, (x, y), (x + w, y + h), (255,0,0), 4)\n",
        "    if x in range(x_prev+5):\n",
        "      continue\n",
        "    else:\n",
        "      x_prev = x\n",
        "      cropped = img[y:y+h, x:x+w]\n",
        "      cy, cx, _ = cropped.shape\n",
        "      if (40 < cx < 140) and (100 < cy < 200):\n",
        "        V = cropped\n",
        "        T = threshold_local(V, 57, offset=15, method=\"gaussian\")\n",
        "        thresh = (V > T).astype(\"uint8\") * 255\n",
        "        thresh = cv2.bitwise_not(thresh)\n",
        "        candidates.append(thresh)\n",
        "  # plt.imshow(imgboxed)\n",
        "  return candidates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTNGU7prDaz6"
      },
      "outputs": [],
      "source": [
        "df_test = pd.read_csv(\"DataTest.csv\", delimiter=';')\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1I0-eG3VEPaF"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "preds = []\n",
        "for test_file in df_test['Name of File'].values:\n",
        "  test_image_path = os.path.join(test_data_dir, test_file)\n",
        "  plate_numbers = preprocess_single(test_image_path)\n",
        "  if len(plate_numbers) == 0:\n",
        "    preds.append('')\n",
        "  else:\n",
        "    plate_num = []\n",
        "    with torch.no_grad():\n",
        "      for char_img in plate_numbers:\n",
        "        out = model_scratch(test_transforms(char_img).unsqueeze(0).to(device))\n",
        "        plate_num.append(torch.argmax(out, 1).cpu().detach().numpy()[0])\n",
        "    preds.append(plate_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Q-NFZS-JwSj"
      },
      "outputs": [],
      "source": [
        "nomor_plat = [1, 27, 1, 1, 1]\n",
        "nomor_plat = [idxtolabel[no] for no in nomor_plat]\n",
        "''.join(nomor_plat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81Awia82EPXM"
      },
      "outputs": [],
      "source": [
        "predicted = []\n",
        "for pred in preds:\n",
        "  if pred == '' :\n",
        "    continue\n",
        "  else :\n",
        "    plate_number = [idxtolabel[num] for num in pred]\n",
        "    predicted.append(''.join(plate_number))\n",
        "\n",
        "predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWR_gf7ZDPQ-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}